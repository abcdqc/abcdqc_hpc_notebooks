{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bids import BIDSLayout\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a bunch of paths\n",
    "mbdu_bids_root = Path('/data/MBDU/ABCD/BIDS/NKI_script/MID')\n",
    "dsst_bids_root = Path('/data/ABCD_DSST/bids_20190215/')\n",
    "mriqc_outdir = Path('/data/ABCD_DSST/bids_20190215/derivatives/mriqc')\n",
    "container_path = Path('/data/ABCD_DSST/containers/poldracklab_mriqc-2018-08-21-8efddd374773.simg')\n",
    "swarm_file = Path('/data/ABCD_DSST/swarms/mriqc_swarm/mriqc_swarm')\n",
    "swarm_log = Path('/data/ABCD_DSST/swarms/mriqc_swarm/logs')\n",
    "# TODO: use semantic versioning or something to find the latest release\n",
    "release_dir = Path('/data/ABCD_DSST/releases/1.1/ABCDstudyDEAP')\n",
    "nprocs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that there aren't any subjects \n",
    "# in DSST bids root that aren't in MBDU bids root\n",
    "\n",
    "mbdu_subs = sorted(list(mbdu_bids_root.glob('sub-*')))\n",
    "mbdu_subs = set([ss.parts[-1] for ss in mbdu_subs])\n",
    "dsst_subs = sorted(list(dsst_bids_root.glob('sub-*')))\n",
    "dsst_subs = set([ss.parts[-1] for ss in dsst_subs])\n",
    "\n",
    "print(f\"{len(dsst_subs.difference(mbdu_subs))} are in DSST that aren't in MBDU\")\n",
    "if len(dsst_subs.difference(mbdu_subs)) > 0:\n",
    "    for ss in dsst_subs.difference(mbdu_subs):\n",
    "        assert ss != ''\n",
    "        ! rm -rf {dsst_bids_root / ss}\n",
    "    \n",
    "mbdu_subs = sorted(list(mbdu_bids_root.glob('sub-*')))\n",
    "mbdu_subs = set([ss.parts[-1] for ss in mbdu_subs])\n",
    "dsst_subs = sorted(list(dsst_bids_root.glob('sub-*')))\n",
    "dsst_subs = set([ss.parts[-1] for ss in dsst_subs])\n",
    "assert len(dsst_subs.difference(mbdu_subs)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = sorted(list(dsst_bids_root.glob('sub-*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_subs = []\n",
    "for sub in subs:\n",
    "    tmp = (sub / 'tmp')\n",
    "    rest = (sub / 'ses-1' / 'rest')\n",
    "    if (tmp.exists()) & (rest.exists()):\n",
    "        bad_subs.append(sub)\n",
    "        \n",
    "# make sure no subjects have the tmp or rest directories\n",
    "assert len(bad_subs) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of subjects in the most recent release\n",
    "# We're assuming that all subjects are in the site table\n",
    "site_df = pd.read_csv(release_dir / 'abcd_lt01.txt',\n",
    "                      skiprows = [1],\n",
    "                      header = 0,\n",
    "                      sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the jsons that have been produced by MRIQC\n",
    "jsons = sorted(list(mriqc_outdir.glob('**/*.json')))\n",
    "\n",
    "json_df = []\n",
    "for sub_json in jsons:\n",
    "    row = {}\n",
    "    row['scan_name'] = sub_json.parts[-1].split('.')[0]\n",
    "    row['path'] = sub_json\n",
    "    json_df.append(row)\n",
    "json_df = pd.DataFrame(json_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all the nifitis and find out which have corresponding html files\n",
    "niis = sorted(list(dsst_bids_root.glob('**/*.nii.gz')))\n",
    "\n",
    "nii_df = []\n",
    "for nii in niis:\n",
    "    row = {}\n",
    "    row['subject'] = nii.parts[4]\n",
    "    row['participant_label'] = row['subject'].split('-')[-1]\n",
    "    row['session'] = nii.parts[5]\n",
    "    row['modality'] = nii.parts[6]\n",
    "    row['scan_name'] = nii.parts[7].split('.')[0]\n",
    "    row['path'] = nii\n",
    "    nii_df.append(row)\n",
    "nii_df = pd.DataFrame(nii_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out which subjects have run, and which had problems\n",
    "mriqc_res_df = nii_df.merge(json_df, how='left', on='scan_name',\n",
    "                            suffixes={'_nii', '_json'}, indicator=True)\n",
    "# _merge variable created as categorical, cast it back to string\n",
    "mriqc_res_df['_merge'] = mriqc_res_df._merge.astype('str')\n",
    "\n",
    "# Make sure that there aren't rows getting duplicated\n",
    "assert len(mriqc_res_df) == len(nii_df)\n",
    "\n",
    "subj_df = pd.DataFrame(mriqc_res_df.groupby('subject').agg({'_merge':['unique', 'nunique']}))\n",
    "\n",
    "problem_subjects = subj_df.index[(subj_df['_merge','nunique'] > 1)].values\n",
    "\n",
    "unrun_subjects = subj_df.index[\n",
    "    (subj_df['_merge','unique'].str[0] == 'left_only')\n",
    "    & (subj_df['_merge','nunique'] == 1)].values\n",
    "\n",
    "finished_subjects = subj_df.index[\n",
    "    (subj_df['_merge','unique'].str[0] == 'both') \n",
    "    & (subj_df['_merge','nunique'] == 1)].values\n",
    "\n",
    "# Make sure that all subjects are either problem, unrun or finished\n",
    "assert len(subj_df) == (len(problem_subjects) \n",
    "                        + len(unrun_subjects)\n",
    "                        + len(finished_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2993 unrun released particpants, 1306 finished released participants, and 57 released participants with problems\n"
     ]
    }
   ],
   "source": [
    "# Find the unfinished subjects that are in our most recent release\n",
    "site_df['participant_label'] = site_df.subjectkey.str.replace('_', '')\n",
    "\n",
    "unrun_participant_labels = set([urs[4:] for urs in unrun_subjects])\n",
    "finished_participant_labels = set([urs[4:] for urs in finished_subjects])\n",
    "problem_participant_labels = set([urs[4:] for urs in problem_subjects])\n",
    "\n",
    "unrun_released_participants = unrun_participant_labels.intersection(set(site_df.participant_label))\n",
    "finished_released_participants = finished_participant_labels.intersection(set(site_df.participant_label))\n",
    "problem_released_participants = problem_participant_labels.intersection(set(site_df.participant_label))\n",
    "\n",
    "print(f\"There are {len(unrun_released_participants)} unrun released particpants,\"\n",
    "      + f\" {len(finished_released_participants)} finished released participants,\"\n",
    "      + f\" and {len(problem_released_participants)} released participants with problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't already have your singularity bind path set,\n",
    "# append this to the front of your command:\n",
    "# export SINGULARITY_BINDPATH=/gs3,/gs4,/gs5,/gs6,/gs7,/gs8,/gs9,/gs10,/gs11,/spin1,/scratch,/fdb,/data,/lscratch &&"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmds = []\n",
    "for sub in unrun_released_participants:\n",
    "    subj_dir = dsst_bids_root / ('sub-' + sub)\n",
    "    cmd = ('mkdir -p /lscratch/$SLURM_JOB_ID/tmp_bids '\n",
    "           + f' && mkdir -p /lscratch/$SLURM_JOB_ID/mriqc_work_{sub} '\n",
    "           + f' && rsync -ach {subj_dir} /lscratch/$SLURM_JOB_ID/tmp_bids/ ' \n",
    "           + f' && singularity run {container_path} --participant_label={sub} --nprocs={nprocs}'\n",
    "           + f' -w /lscratch/$SLURM_JOB_ID/mriqc_work_{sub}'\n",
    "           + f' /lscratch/$SLURM_JOB_ID/tmp_bids/ {mriqc_outdir} participant')\n",
    "    cmds.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mkdir -p /lscratch/$SLURM_JOB_ID/tmp_bids  && mkdir -p /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVWHCJ7UWF  && rsync -ach /data/ABCD_DSST/bids_20190215/sub-NDARINVWHCJ7UWF /lscratch/$SLURM_JOB_ID/tmp_bids/  && singularity run /data/ABCD_DSST/containers/poldracklab_mriqc-2018-08-21-8efddd374773.simg --participant_label=NDARINVWHCJ7UWF --nprocs=20 -w /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVWHCJ7UWF /lscratch/$SLURM_JOB_ID/tmp_bids/ /data/ABCD_DSST/bids_20190215/derivatives/mriqc participant',\n",
       " 'mkdir -p /lscratch/$SLURM_JOB_ID/tmp_bids  && mkdir -p /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVDYP4KLFJ  && rsync -ach /data/ABCD_DSST/bids_20190215/sub-NDARINVDYP4KLFJ /lscratch/$SLURM_JOB_ID/tmp_bids/  && singularity run /data/ABCD_DSST/containers/poldracklab_mriqc-2018-08-21-8efddd374773.simg --participant_label=NDARINVDYP4KLFJ --nprocs=20 -w /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVDYP4KLFJ /lscratch/$SLURM_JOB_ID/tmp_bids/ /data/ABCD_DSST/bids_20190215/derivatives/mriqc participant',\n",
       " 'mkdir -p /lscratch/$SLURM_JOB_ID/tmp_bids  && mkdir -p /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVNU9AXHPG  && rsync -ach /data/ABCD_DSST/bids_20190215/sub-NDARINVNU9AXHPG /lscratch/$SLURM_JOB_ID/tmp_bids/  && singularity run /data/ABCD_DSST/containers/poldracklab_mriqc-2018-08-21-8efddd374773.simg --participant_label=NDARINVNU9AXHPG --nprocs=20 -w /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVNU9AXHPG /lscratch/$SLURM_JOB_ID/tmp_bids/ /data/ABCD_DSST/bids_20190215/derivatives/mriqc participant',\n",
       " 'mkdir -p /lscratch/$SLURM_JOB_ID/tmp_bids  && mkdir -p /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVA70DPKY0  && rsync -ach /data/ABCD_DSST/bids_20190215/sub-NDARINVA70DPKY0 /lscratch/$SLURM_JOB_ID/tmp_bids/  && singularity run /data/ABCD_DSST/containers/poldracklab_mriqc-2018-08-21-8efddd374773.simg --participant_label=NDARINVA70DPKY0 --nprocs=20 -w /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVA70DPKY0 /lscratch/$SLURM_JOB_ID/tmp_bids/ /data/ABCD_DSST/bids_20190215/derivatives/mriqc participant',\n",
       " 'mkdir -p /lscratch/$SLURM_JOB_ID/tmp_bids  && mkdir -p /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVM2EJE47J  && rsync -ach /data/ABCD_DSST/bids_20190215/sub-NDARINVM2EJE47J /lscratch/$SLURM_JOB_ID/tmp_bids/  && singularity run /data/ABCD_DSST/containers/poldracklab_mriqc-2018-08-21-8efddd374773.simg --participant_label=NDARINVM2EJE47J --nprocs=20 -w /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVM2EJE47J /lscratch/$SLURM_JOB_ID/tmp_bids/ /data/ABCD_DSST/bids_20190215/derivatives/mriqc participant',\n",
       " 'mkdir -p /lscratch/$SLURM_JOB_ID/tmp_bids  && mkdir -p /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVGZJDGF8L  && rsync -ach /data/ABCD_DSST/bids_20190215/sub-NDARINVGZJDGF8L /lscratch/$SLURM_JOB_ID/tmp_bids/  && singularity run /data/ABCD_DSST/containers/poldracklab_mriqc-2018-08-21-8efddd374773.simg --participant_label=NDARINVGZJDGF8L --nprocs=20 -w /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVGZJDGF8L /lscratch/$SLURM_JOB_ID/tmp_bids/ /data/ABCD_DSST/bids_20190215/derivatives/mriqc participant',\n",
       " 'mkdir -p /lscratch/$SLURM_JOB_ID/tmp_bids  && mkdir -p /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVKBR8U1TH  && rsync -ach /data/ABCD_DSST/bids_20190215/sub-NDARINVKBR8U1TH /lscratch/$SLURM_JOB_ID/tmp_bids/  && singularity run /data/ABCD_DSST/containers/poldracklab_mriqc-2018-08-21-8efddd374773.simg --participant_label=NDARINVKBR8U1TH --nprocs=20 -w /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVKBR8U1TH /lscratch/$SLURM_JOB_ID/tmp_bids/ /data/ABCD_DSST/bids_20190215/derivatives/mriqc participant',\n",
       " 'mkdir -p /lscratch/$SLURM_JOB_ID/tmp_bids  && mkdir -p /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVHFZ6EMM2  && rsync -ach /data/ABCD_DSST/bids_20190215/sub-NDARINVHFZ6EMM2 /lscratch/$SLURM_JOB_ID/tmp_bids/  && singularity run /data/ABCD_DSST/containers/poldracklab_mriqc-2018-08-21-8efddd374773.simg --participant_label=NDARINVHFZ6EMM2 --nprocs=20 -w /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVHFZ6EMM2 /lscratch/$SLURM_JOB_ID/tmp_bids/ /data/ABCD_DSST/bids_20190215/derivatives/mriqc participant',\n",
       " 'mkdir -p /lscratch/$SLURM_JOB_ID/tmp_bids  && mkdir -p /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVB97H0LH3  && rsync -ach /data/ABCD_DSST/bids_20190215/sub-NDARINVB97H0LH3 /lscratch/$SLURM_JOB_ID/tmp_bids/  && singularity run /data/ABCD_DSST/containers/poldracklab_mriqc-2018-08-21-8efddd374773.simg --participant_label=NDARINVB97H0LH3 --nprocs=20 -w /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVB97H0LH3 /lscratch/$SLURM_JOB_ID/tmp_bids/ /data/ABCD_DSST/bids_20190215/derivatives/mriqc participant',\n",
       " 'mkdir -p /lscratch/$SLURM_JOB_ID/tmp_bids  && mkdir -p /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVF1E6TJJ9  && rsync -ach /data/ABCD_DSST/bids_20190215/sub-NDARINVF1E6TJJ9 /lscratch/$SLURM_JOB_ID/tmp_bids/  && singularity run /data/ABCD_DSST/containers/poldracklab_mriqc-2018-08-21-8efddd374773.simg --participant_label=NDARINVF1E6TJJ9 --nprocs=20 -w /lscratch/$SLURM_JOB_ID/mriqc_work_NDARINVF1E6TJJ9 /lscratch/$SLURM_JOB_ID/tmp_bids/ /data/ABCD_DSST/bids_20190215/derivatives/mriqc participant']"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test swarm command with two subjects\n",
    "swarm_file.write_text('\\n'.join(cmds[:10]))\n",
    "swarm_file.read_text().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20735678\r\n"
     ]
    }
   ],
   "source": [
    "!swarm -m singularity,webproxy -f {swarm_file} -g 24 -t {nprocs} --maxrunning 10 --partition norm,quick --logdir {swarm_log} --time 1:00:00 --gres=lscratch:100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
